{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "In this assignment, you will implement a K-Means Clustering algorithm from scratch and compare the results to existing sklearn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1: Write a method that determine Labels from Points and ClusterCentroids, and return a list of a label for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FindLabelOfClosest(Points, ClusterCentroids): # determine Labels from Points and ClusterCentroids\n",
    "    #TODO\n",
    "    NumberOfClusters, NumberOfDimensions = ClusterCentroids.shape # dimensions of the initial Centroids\n",
    "    Distances = #TODO # centroid distances\n",
    "    NumberOfPoints, NumberOfDimensions = Points.shape\n",
    "    Labels = #TODO\n",
    "    for PointNumber in range(NumberOfPoints): # assign labels to all data points            \n",
    "        for ClusterNumber in range(NumberOfClusters): # for each cluster\n",
    "            # Get distances for each cluster\n",
    "            Distances[ClusterNumber] = #TODO               \n",
    "        Labels[PointNumber] = #TODO # assign to closest cluster\n",
    "    return Labels # return the a label for each point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.2: Write a method that determine centroid of Points with the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateClusterCentroid(Points, Labels): # determine centroid of Points with the same label\n",
    "    #TODO\n",
    "    ClusterLabels = np.unique(Labels) # names of labels\n",
    "    NumberOfPoints, NumberOfDimensions = Points.shape\n",
    "    ClusterCentroids = #TODO\n",
    "    for ClusterNumber in ClusterLabels: # for each cluster\n",
    "        # get mean for each label \n",
    "        ClusterCentroids.loc[ClusterNumber, :] = #TODO\n",
    "    return ClusterCentroids # return the a label for each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.3: Put it all together as such. K-means algorithm partitions the input data into K clusters by iterating between the following two steps:\n",
    "- Compute the cluster center by computing the arithmetic mean of all the points belonging to the cluster.\n",
    "- Assign each point to the closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(Points, ClusterCentroidGuesses):\n",
    "    #TODO\n",
    "    ClusterCentroids = ClusterCentroidGuesses.copy()\n",
    "    Labels_Previous = None\n",
    "    # Get starting set of labels\n",
    "    Labels = FindLabelOfClosest(Points, ClusterCentroids)\n",
    "    while not np.array_equal(Labels, Labels_Previous):\n",
    "        # Re-calculate cluster centers based on new set of labels\n",
    "        ClusterCentroids = #TODO\n",
    "        Labels_Previous = Labels.copy() # Must make a deep copy\n",
    "        # Determine new labels based on new cluster centers\n",
    "        Labels = #TODO\n",
    "    return Labels, ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StoreTxn = pd.read_csv(\"./Superstore Transaction data.csv\")\n",
    "StoreTxn['Order Date'] = pd.to_datetime(StoreTxn['Order Date'] )\n",
    "StoreTxn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract RFM features from the transaction data:\n",
    "- Recency: when was the last purchase they made\n",
    "- Frequency: how often do they make a purchase in the last month (or any given window you choose)\n",
    "- Monetary: how much money did they spend in the last month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1:\n",
    "- Use groupby to summarize the quantity and dollar columns by user_id and date\n",
    "- Name the aggregated data txn_agg\n",
    "- Reset the index for txn_agg to the default and user_id and date to dataframe columns\n",
    "- Confirm changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_agg = #TODO #Summarize quantity and dollar by user_id - date.  \n",
    "txn_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.2:Using the aggregated data, obtain recency, frequency and monetary features for both dollar and quantity. Use a 7-day moving window for frequency and monetary. Call your new features last_visit_ndays (recency) quantity_roll_sum_7D (frequency) and dollar_roll_sum_7D (monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last = #TODO # Group the data by user_id and calculate lag as the differnce between the current and previous date (lag by one period)\n",
    "last.rename(columns = {'Order Date' : 'last_visit_ndays'}, inplace = True) # Name the lagged date values last_visit_ndays\n",
    "print(last.head(10), end='\\n\\n')\n",
    "\n",
    "roll = #TODO # Group the data by user_id.  Apply a 7 day offset to implement a moving 7-day window totaling quantity and dollars sold within each time window. \n",
    "roll.rename(columns = {'Quantity' : 'Quantity_roll_sum_7D', 'Sales' : 'Sales_roll_sum_7D'}, inplace = True) # Name the resulting data values quantity_roll_sum_7D and dollar_roll_sum_7D\n",
    "print(roll.head(10), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.3: Combine all three features into a single DataFrame and call it txn_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_roll = #TODO # Inner join between roll (frequency and monetary fields) and last (recency fields) to create churn_roll.  Join based on index which works given that both dataframes are sorted by user_id and date.\n",
    "\n",
    "print(txn_roll.dtypes, end='\\n\\n')\n",
    "txn_roll.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.4: Use fillna to replace missing values for recency with a large value like 100 days (whatever makes business sense). HINT: You can use pd.Timedelta('100 days') to set the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_roll['last_visit_ndays'] = #TODO # Replace missing recency values with 1000 days\n",
    "txn_roll.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.5: Merge the aggregated data churn_agg with the RFM features in churn_roll. You can use the merge method to do this with the right keys specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_rfm = #TODO #merge on Customer ID and Order Date\n",
    "txn_rfm.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.1: Train the k-means algorithm you developed earlier on the RFM features using  ùëò=4 . What are the cluster centroids? The cluster centroids should be reported in the original scale, not the standardized scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterCentroidGuesses = #TODO\n",
    "\n",
    "Labels, ClusterCentroids = KMeans(txn_rfm, ClusterCentroidGuesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.2: Pick few pairs and plot scatter plots along with cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bonus] Question 4: Train k-means model using sklearn library and compare results to the model developed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
