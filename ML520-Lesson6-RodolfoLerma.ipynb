{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (Assignment 6)\n",
    "\n",
    "## Student: Rodolfo Lerma\n",
    "\n",
    "In this assignment, you will implement a K-Means Clustering algorithm from scratch and compare the results to existing sklearn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1: Write a method that determine Labels from Points and ClusterCentroids, and return a list of a label for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FindLabelOfClosest(Points, ClusterCentroids): # determine Labels from Points and ClusterCentroids\n",
    "    #TODO\n",
    "    NumberOfClusters, NumberOfDimensions = ClusterCentroids.shape # dimensions of the initial Centroids\n",
    "    Distances = #TODO # centroid distances\n",
    "    NumberOfPoints, NumberOfDimensions = Points.shape\n",
    "    Labels = #TODO\n",
    "    for PointNumber in range(NumberOfPoints): # assign labels to all data points            \n",
    "        for ClusterNumber in range(NumberOfClusters): # for each cluster\n",
    "            # Get distances for each cluster\n",
    "            Distances[ClusterNumber] = #TODO               \n",
    "        Labels[PointNumber] = #TODO # assign to closest cluster\n",
    "    return Labels # return the a label for each point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2: Write a method that determine centroid of Points with the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateClusterCentroid(Points, Labels): # determine centroid of Points with the same label\n",
    "    #TODO\n",
    "    ClusterLabels = np.unique(Labels) # names of labels\n",
    "    NumberOfPoints, NumberOfDimensions = Points.shape\n",
    "    ClusterCentroids = #TODO\n",
    "    for ClusterNumber in ClusterLabels: # for each cluster\n",
    "        # get mean for each label \n",
    "        ClusterCentroids.loc[ClusterNumber, :] = #TODO\n",
    "    return ClusterCentroids # return the a label for each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3: Put it all together as such. K-means algorithm partitions the input data into K clusters by iterating between the following two steps:\n",
    "- Compute the cluster center by computing the arithmetic mean of all the points belonging to the cluster.\n",
    "- Assign each point to the closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(Points, ClusterCentroidGuesses):\n",
    "    #TODO\n",
    "    ClusterCentroids = ClusterCentroidGuesses.copy()\n",
    "    Labels_Previous = None\n",
    "    # Get starting set of labels\n",
    "    Labels = FindLabelOfClosest(Points, ClusterCentroids)\n",
    "    while not np.array_equal(Labels, Labels_Previous):\n",
    "        # Re-calculate cluster centers based on new set of labels\n",
    "        ClusterCentroids = #TODO\n",
    "        Labels_Previous = Labels.copy() # Must make a deep copy\n",
    "        # Determine new labels based on new cluster centers\n",
    "        Labels = #TODO\n",
    "    return Labels, ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StoreTxn = pd.read_csv(\"./Superstore Transaction data.csv\")\n",
    "StoreTxn['Order Date'] = pd.to_datetime(StoreTxn['Order Date'] )\n",
    "StoreTxn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract RFM features from the transaction data:\n",
    "- Recency: when was the last purchase they made\n",
    "- Frequency: how often do they make a purchase in the last month (or any given window you choose)\n",
    "- Monetary: how much money did they spend in the last month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1:\n",
    "- Use groupby to summarize the quantity and dollar columns by user_id and date\n",
    "- Name the aggregated data txn_agg\n",
    "- Reset the index for txn_agg to the default and user_id and date to dataframe columns\n",
    "- Confirm changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_agg = #TODO #Summarize quantity and dollar by user_id - date.  \n",
    "txn_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2:Using the aggregated data, obtain recency, frequency and monetary features for both dollar and quantity. Use a 7-day moving window for frequency and monetary. Call your new features last_visit_ndays (recency) quantity_roll_sum_7D (frequency) and dollar_roll_sum_7D (monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last = #TODO # Group the data by user_id and calculate lag as the differnce between the current and previous date (lag by one period)\n",
    "last.rename(columns = {'Order Date' : 'last_visit_ndays'}, inplace = True) # Name the lagged date values last_visit_ndays\n",
    "print(last.head(10), end='\\n\\n')\n",
    "\n",
    "roll = #TODO # Group the data by user_id.  Apply a 7 day offset to implement a moving 7-day window totaling quantity and dollars sold within each time window. \n",
    "roll.rename(columns = {'Quantity' : 'Quantity_roll_sum_7D', 'Sales' : 'Sales_roll_sum_7D'}, inplace = True) # Name the resulting data values quantity_roll_sum_7D and dollar_roll_sum_7D\n",
    "print(roll.head(10), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3: Combine all three features into a single DataFrame and call it txn_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_roll = #TODO # Inner join between roll (frequency and monetary fields) and last (recency fields) to create churn_roll.  Join based on index which works given that both dataframes are sorted by user_id and date.\n",
    "\n",
    "print(txn_roll.dtypes, end='\\n\\n')\n",
    "txn_roll.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4: Use fillna to replace missing values for recency with a large value like 100 days (whatever makes business sense). HINT: You can use pd.Timedelta('100 days') to set the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_roll['last_visit_ndays'] = #TODO # Replace missing recency values with 1000 days\n",
    "txn_roll.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5: Merge the aggregated data churn_agg with the RFM features in churn_roll. You can use the merge method to do this with the right keys specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_rfm = #TODO #merge on Customer ID and Order Date\n",
    "txn_rfm.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1: Train the k-means algorithm you developed earlier on the RFM features using  ùëò=4 . What are the cluster centroids? The cluster centroids should be reported in the original scale, not the standardized scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterCentroidGuesses = #TODO\n",
    "\n",
    "Labels, ClusterCentroids = KMeans(txn_rfm, ClusterCentroidGuesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2: Pick few pairs and plot scatter plots along with cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bonus] Question 4: Train k-means model using sklearn library and compare results to the model developed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: \n",
    "- What was your incoming experience with this model, if any? \n",
    "- What steps you took, what obstacles you encountered?\n",
    "- How you link this exercise to real-world, machine learning problem-solving. \n",
    "- What steps were missing? What else do you need to learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 1](https://euanrussano.github.io/20190813kmeans/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 2](https://www.askpython.com/python/examples/k-means-clustering-from-scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 3](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 4](https://medium.com/p/6a9d19cafc25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 5](https://jermwatt.github.io/machine_learning_refined/notes/8_Linear_unsupervised_learning/8_5_Kmeans.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 6](https://medium.com/machine-learning-algorithms-from-scratch/k-means-clustering-from-scratch-in-python-1675d38eee42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 7](https://github.com/tugot17/K-Means-Algorithm-From-Scratch/blob/master/K-means.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Example 8](https://www.python-engineer.com/courses/mlfromscratch/12_kmeans/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 9](https://regenerativetoday.com/develop-a-k-mean-clustering-algorithm-from-scratch-in-python-and-use-it-for-dimensional-reduction/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
